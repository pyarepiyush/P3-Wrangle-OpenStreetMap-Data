{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample file from initial OSM file download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#########################################\n",
    "# Create a sample file for initial study\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"san-francisco_california.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sf_sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial study of the OSM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import string\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "#from sets import Set\n",
    "\n",
    "\n",
    "    \n",
    "###################################\n",
    "# Study components of the OSM file\n",
    "\n",
    "dist_tags = defaultdict(int)\n",
    "# Count instance of distinct tags\n",
    "def count_tags(elem,elem_tag):\n",
    "    \n",
    "    if elem.tag == elem_tag:\n",
    "        \n",
    "        for elements in elem.iter(None):\n",
    "            #print elements.tag\n",
    "\n",
    "            dist_tags[elements.tag] +=1\n",
    "           \n",
    "    return dist_tags\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return counts of values for tag attribute\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "alltags={}\n",
    "alltags[\"lower\"]= defaultdict(int)\n",
    "alltags[\"lower_colon\"]= defaultdict(int)\n",
    "alltags[\"problemchars\"]= defaultdict(int)\n",
    "alltags[\"others\"]= defaultdict(int)\n",
    "\n",
    "def tag_values(event,elem,elem_tag):\n",
    "    if elem.tag ==elem_tag:\n",
    "        for elements in elem.iter('tag'): \n",
    "            if re.match(lower,elements.attrib['k']):\n",
    "                alltags[\"lower\"][elements.attrib['k']]+=1\n",
    "            elif re.match(lower_colon,elements.attrib['k']):\n",
    "                alltags[\"lower_colon\"][elements.attrib['k']]+=1         \n",
    "            elif re.match(problemchars,elements.attrib['k']):\n",
    "                alltags[\"problemchars\"][elements.attrib['k']]+=1 \n",
    "            else:\n",
    "                 alltags[\"others\"][elements.attrib['k']]+=1\n",
    "            \n",
    "\n",
    "    return alltags\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return counts of values for tag attribute\n",
    "\n",
    "\n",
    "\n",
    "zip_val= defaultdict(set)\n",
    "\n",
    "def zip_values(event,elem,elem_tag):\n",
    "    if elem.tag == elem_tag:\n",
    "        for elements in elem.iter('tag'):\n",
    "            if 'zip' in elements.attrib['k'] and len(elements.attrib['v']) > 6:\n",
    "                zip_val[elements.attrib['k']].add( elements.attrib['v']  )         \n",
    "    return zip_val\n",
    "\n",
    "\n",
    "    \n",
    "# Check Address values\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Real\", \"Terrace\", \"Way\", \"Circle\",\"Highway\"]\n",
    "\n",
    "pattern = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "address = defaultdict(set)\n",
    "\n",
    "def address_values(elem,elem_tag):\n",
    "    #addr= defaultdict(set)\n",
    "    if elem.tag == elem_tag:\n",
    "        for elements in elem.iter('tag'): \n",
    "            if elements.attrib['k'] == 'addr:street':\n",
    "                m = pattern.search(elements.attrib['v'])\n",
    "                if m:\n",
    "                    addr_type = m.group()                \n",
    "                    if addr_type not in expected:\n",
    "                        address[addr_type].add(elements.attrib['v'] ) \n",
    "    #print address\n",
    "    return address\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sort by value and print top 20 sorted list\n",
    "def print_sorted_list(d, message):\n",
    "    a = sorted(d.iteritems(), key = lambda (k,v): (-v,k)) \n",
    "    for i,key in enumerate(a):\n",
    "        if i<21:\n",
    "             print i,key\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Read and Parse the osm file \n",
    "counter=0\n",
    "n_tags={}\n",
    "ktag_values = {}\n",
    "address_val = {}\n",
    "county_list = {}\n",
    "\n",
    "\n",
    "\n",
    "def read_file(filename,elem_tag):\n",
    "    global counter \n",
    "    global n_tags \n",
    "    global ktag_values \n",
    "    global address_val \n",
    "    global county_list\n",
    "    for event, elem in ET.iterparse(filename):        \n",
    "\n",
    "        n_tags =count_tags(elem,elem_tag)  \n",
    "        ktag_values = tag_values(event,elem,elem_tag)\n",
    "        address_val = address_values(elem,elem_tag)\n",
    "        zip_val= zip_values(event,elem,elem_tag)\n",
    "        \n",
    "         # Check distinct county names and determine any inconsistensies\n",
    "     \n",
    "\n",
    "        # Check county values\n",
    "        if counter==0:\n",
    "            county_list=defaultdict(set)\n",
    "\n",
    "        if elem.tag == elem_tag:       \n",
    "            for elements in elem.iter('tag'):\n",
    "                if ':county' in elements.attrib['k']:            \n",
    "\n",
    "                    county_list[elements.attrib['k']].add(elements.attrib['v'])\n",
    "        \n",
    "        \n",
    "            counter+=1       \n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     read_file('sf_sample.osm','way')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check resulting value from initial study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ct Distinct upper-level tag :  defaultdict(<type 'int'>, {'tag': 161093, 'nd': 667859, 'way': 68095})\n"
     ]
    }
   ],
   "source": [
    "# Print Distinct upper level tags       \n",
    "print\n",
    "print \"Ct Distinct upper-level tag : \", n_tags\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------\n",
      "values of keys that are  problemchars\n",
      "--------------\n",
      "values of keys that are  lower\n",
      "0 ('highway', 2585)\n",
      "1 ('name', 1771)\n",
      "2 ('created_by', 1280)\n",
      "3 ('amenity', 1275)\n",
      "4 ('source', 791)\n",
      "5 ('crossing', 744)\n",
      "6 ('shop', 483)\n",
      "7 ('natural', 400)\n",
      "8 ('taxon', 297)\n",
      "9 ('ele', 258)\n",
      "10 ('power', 246)\n",
      "11 ('cuisine', 244)\n",
      "12 ('operator', 228)\n",
      "13 ('railway', 224)\n",
      "14 ('website', 218)\n",
      "15 ('phone', 170)\n",
      "16 ('leaf_cycle', 164)\n",
      "17 ('leaf_type', 152)\n",
      "18 ('barrier', 140)\n",
      "19 ('traffic_calming', 140)\n",
      "20 ('emergency', 130)\n",
      "--------------\n",
      "values of keys that are  lower_colon\n",
      "0 ('addr:housenumber', 2430)\n",
      "1 ('addr:street', 2192)\n",
      "2 ('addr:city', 1804)\n",
      "3 ('addr:postcode', 740)\n",
      "4 ('addr:state', 630)\n",
      "5 ('addr:country', 396)\n",
      "6 ('species:en', 291)\n",
      "7 ('redwood_city_ca:addr_id', 288)\n",
      "8 ('gnis:feature_id', 222)\n",
      "9 ('gnis:created', 192)\n",
      "10 ('gnis:county_id', 182)\n",
      "11 ('gnis:state_id', 182)\n",
      "12 ('seamark:type', 59)\n",
      "13 ('gnis:county_name', 41)\n",
      "14 ('survey:date', 38)\n",
      "15 ('traffic_signals:sound', 33)\n",
      "16 ('gnis:import_uuid', 29)\n",
      "17 ('gnis:reviewed', 29)\n",
      "18 ('gnis:id', 23)\n",
      "19 ('source:pkey', 21)\n",
      "20 ('fire_hydrant:type', 17)\n",
      "--------------\n",
      "values of keys that are  others\n",
      "0 ('gnis:Class', 23)\n",
      "1 ('gnis:County', 23)\n",
      "2 ('gnis:County_num', 23)\n",
      "3 ('gnis:ST_alpha', 23)\n",
      "4 ('gnis:ST_num', 23)\n",
      "5 ('seamark:beacon_lateral:category', 14)\n",
      "6 ('seamark:beacon_lateral:colour', 14)\n",
      "7 ('seamark:beacon_lateral:shape', 14)\n",
      "8 ('Subclass', 12)\n",
      "9 ('Trunk_Diam', 12)\n",
      "10 ('seamark:light:character', 11)\n",
      "11 ('seamark:light:period', 11)\n",
      "12 ('seamark:light:colour', 10)\n",
      "13 ('seamark:rock:water_level', 9)\n",
      "14 ('seamark:light:range', 8)\n",
      "15 ('seamark:light:sequence', 8)\n",
      "16 ('seamark:rock:quality', 8)\n",
      "17 ('FIXME', 6)\n",
      "18 ('seamark:daymark:colour', 6)\n",
      "19 ('seamark:daymark:colour_pattern', 6)\n",
      "20 ('seamark:daymark:shape', 6)\n"
     ]
    }
   ],
   "source": [
    "# Count of different types of keys\n",
    "print\n",
    "for k in ktag_values.keys():\n",
    "    print '--------------'\n",
    "    print 'values of keys that are ', k\n",
    "    print_sorted_list(ktag_values[k], 'Top 20 k values')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Address Types: \n",
      "defaultdict(<type 'set'>, {'Bridgeway': set(['Bridgeway']), 'St.': set(['Webster St.']), 'Cres': set(['Wellesley Cres']), 'Rd': set(['Ascot Rd']), 'Pulgas': set(['Alameda de Las Pulgas', 'Alamed de las Pulgas']), 'East': set(['Francisco Boulevard East']), 'Alameda': set(['The Alameda']), 'D': set(['Marina Boulevard Building D']), 'avenue': set(['Santa Cruz avenue']), 'Plz': set(['Woodside Plz']), 'Embarcadero': set(['The Embarcadero']), '730': set(['Sansome Street Ste 730']), 'way': set(['Orinda way']), 'Path': set(['Indian Rock Path', 'Parnassus Path']), 'Post': set(['Post']), 'Building': set(['Multi Use Building']), 'Center': set(['Westlake Center', 'South Shore Center', 'Bon Air Center']), 'Plaza': set(['Manor Plaza', 'Mint Plaza', 'Civic Center Plaza']), 'St': set(['Park St', '24th St']), 'Ave': set(['Floribunda Ave', 'Geneva Ave', 'Thorton Ave']), '100': set(['Woodside Road, Suite 100']), 'Bay': set(['Bay']), 'Blvd.': set(['East Francisco Blvd.']), '39': set(['Pier 39']), '3500': set(['Sansome St #3500']), 'Alley': set(['Hodges Alley']), 'Walk': set(['Rose Walk', 'Terrace Walk']), 'Blvd': set(['Ardenwood Blvd', 'Tice Valley Blvd', 'Canal Blvd', 'Newark Blvd', 'Skyline Blvd']), 'Broadway': set(['Broadway'])})\n"
     ]
    }
   ],
   "source": [
    "  # print Address types with address values as arrays\n",
    "print    \n",
    "print \"Address Types: \" \n",
    "pprint.pprint(address_val) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for counties\n",
      "defaultdict(<type 'set'>, {'addr:county': set(['Contra Costa', 'Alameda']), 'gnis:county_name': set(['Marin', 'San Francisco', 'Contra Costa', 'Alameda', 'San Mateo']), 'gnis:county_id': set(['075', '081', '085', '001', '013', '041'])})\n"
     ]
    }
   ],
   "source": [
    "# print county list\n",
    "    \n",
    "print \"Unique values for counties\"\n",
    "print county_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip Values\n",
      "{'tiger:zip_left': set(['94014; 94112',\n",
      "                        '94037; 94044',\n",
      "                        '94109;94115',\n",
      "                        '94112; 94131',\n",
      "                        '94112;94127',\n",
      "                        '94115; 94123',\n",
      "                        '94526; 94507',\n",
      "                        '94530:94801',\n",
      "                        '94605:94621',\n",
      "                        '94605; 94619',\n",
      "                        '94607; 94608',\n",
      "                        '94703:94709',\n",
      "                        '94704; 94609',\n",
      "                        '94925; 94920',\n",
      "                        '94941:94965']),\n",
      " 'tiger:zip_right': set(['94014; 94112',\n",
      "                         '94109;94115',\n",
      "                         '94526; 94507',\n",
      "                         '94530:94801',\n",
      "                         '94605:94621',\n",
      "                         '94607; 94608',\n",
      "                         '94703:94709',\n",
      "                         '94704; 94609',\n",
      "                         '94925; 94920',\n",
      "                         '94941:94965'])}\n"
     ]
    }
   ],
   "source": [
    "# print distinct keys for zip and their values\n",
    "    \n",
    "print \"Zip Values\"\n",
    "pprint.pprint(dict(zip_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to clean the data (where problems are detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to clean the data\n",
    "\n",
    "# update Address values   \n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\":\"Avenue\",\n",
    "            \"Rd\":\"Road\",\n",
    "            \"Pl\":\"Place\",\n",
    "            \"Blvd\":\"Boulevard\",\n",
    "            \"Ave\":\"Avenue\",\n",
    "            \"avenue\":\"Avenue\"\n",
    "            }\n",
    "\n",
    "\n",
    "def update_address(name):    \n",
    "\n",
    "    for k,v in mapping.iteritems():\n",
    "        m = pattern.search(name)\n",
    "        #print 'm.group() -->',m.group()\n",
    "        #print 'Old Name -->',name\n",
    "        if m:\n",
    "            if m.group() == k:\n",
    "                name = string.replace(name, k, v, 1)\n",
    "                #print 'Map -->',k,':',v,'| ', 'Changed Name -->',name\n",
    "                break\n",
    "            \n",
    "\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "# Update county values\n",
    "def update_county(county):\n",
    "    \n",
    "    # remove , CA from county names if exists    \n",
    "    if ',' in county:\n",
    "        pos=county.index(\",\")\n",
    "        county=county[:pos]\n",
    "    \n",
    "    return county\n",
    "    \n",
    "    \n",
    "\n",
    "# Update zip values: If zipcodeis longer than 6 characters, keep first 6 characters only \n",
    "def update_zip(zip):\n",
    "    \n",
    "    if len(zip)>6:\n",
    "        zip = zip[:5]\n",
    "    \n",
    "    return zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data where needed and save the results in JSON file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "\n",
    "pattern_county = re.compile(r':county[_name]*$')\n",
    "pattern_zip = re.compile(r'zip|postcode')\n",
    "pattern_digit = re.compile(r'^\\d*\\d$')\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "                    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        \n",
    "        '''\n",
    "        - all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "            - attributes in the CREATED array should be added under a key \"created\"\n",
    "            - attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "              for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "              and not strings. \n",
    "        '''\n",
    "        node[\"created\"] = {}\n",
    "        node[\"pos\"] = []       \n",
    "        node[\"type\"] = element.tag\n",
    "        \n",
    "        for key, value in element.attrib.items():\n",
    "                \n",
    "                \n",
    "            if key in CREATED:\n",
    "                node[\"created\"][key] = value\n",
    "\n",
    "            elif key in [\"lat\",\"lon\"]:\n",
    "                node[\"pos\"].insert(0,float(value))\n",
    "                \n",
    "            else:\n",
    "                node[key]  = value\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        ''' \n",
    "        - if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "        - if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "        - if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n",
    "          process it in a way that you feel is best. For example, you might split it into a two-level\n",
    "          dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        create_addr = 0\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            \n",
    "            # if the values are not problematic, start populating the dictionary\n",
    "            if not(re.search(problemchars, tag.attrib[\"k\"])):\n",
    "                \n",
    "                '''or 'zip' in element.attrib[\"k\"]:'''\n",
    "                # Initialize dict address\n",
    "                if (tag.attrib[\"k\"][:5]==\"addr:\" and tag.attrib[\"k\"].count(':') == 1) or pattern_county.search(tag.attrib[\"k\"]) or pattern_zip.search(tag.attrib[\"k\"]):\n",
    "                    if create_addr==0:\n",
    "                        node[\"address\"]={}\n",
    "                    create_addr = 1                   \n",
    "\n",
    "\n",
    "                # if tag attribute is :addr\n",
    "                if tag.attrib[\"k\"][:5]==\"addr:\":\n",
    "                    \n",
    "                    \n",
    "                    # Initialize dict address\n",
    "                    #if tag.attrib[\"k\"].count(':') == 1:\n",
    "                        #if create_addr==0:\n",
    "                            #node[\"address\"]={}\n",
    "                        #create_addr = 1            \n",
    "                        \n",
    "                    # Update county values and populate\n",
    "                    if pattern_county.search(tag.attrib[\"k\"]):\n",
    "                        node[\"address\"][\"county\"] = update_county(tag.attrib[\"v\"])\n",
    "                        \n",
    "                    # Update zip values and populate  \n",
    "                    elif  pattern_zip.search(tag.attrib[\"k\"]):\n",
    "                        node[\"address\"][\"zip\"] = update_zip(tag.attrib[\"v\"])                    \n",
    "\n",
    "                    # Update street values and populate  \n",
    "                    elif tag.attrib[\"k\"][5:] == 'street':\n",
    "                        node[\"address\"][\"street\"] = update_address(tag.attrib[\"v\"])\n",
    "\n",
    "                    # Remaining\n",
    "                    else:\n",
    "                        node[\"address\"][tag.attrib[\"k\"][5:]] = tag.attrib[\"v\"]\n",
    "\n",
    "                # if tag attribute is not :addr\n",
    "                elif tag.attrib[\"k\"][:5] != 'addr:':\n",
    "                   \n",
    "                    # Update county values\n",
    "                    if pattern_county.search(tag.attrib[\"k\"]):\n",
    "                        node[\"address\"][\"county\"] = update_county(tag.attrib[\"v\"])\n",
    "                        \n",
    "                    # Update zip values and populate  \n",
    "                    elif  pattern_zip.search(tag.attrib[\"k\"]):\n",
    "                        node[\"address\"][\"zip\"] = update_zip(tag.attrib[\"v\"])  \n",
    "                        \n",
    "                    # Remove non-integer characters from building-levels\n",
    "                    elif tag.attrib[\"k\"] ==\"building:levels\":\n",
    "                        if pattern_digit.search(tag.attrib[\"v\"]):\n",
    "                            node[tag.attrib[\"k\"]] =  int(tag.attrib[\"v\"])\n",
    "                        \n",
    "                    else:\n",
    "                        node[tag.attrib[\"k\"]] =  tag.attrib[\"v\"]\n",
    "  \n",
    "  \n",
    "        create_node_ref=0\n",
    "        if element.tag == \"way\":\n",
    "            for nd in element.iter(\"nd\"):\n",
    "                if  create_node_ref==0:\n",
    "                    node[\"node_refs\"] = []\n",
    "                create_node_ref=1    \n",
    "                node[\"node_refs\"].append(nd.attrib[\"ref\"])\n",
    "                \n",
    "\n",
    "        #pprint.pprint(dict(node))\n",
    "        return node\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "    #print node\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        counter_nodes=0\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "# call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "# additional spaces to the output, making it significantly larger.\n",
    "data = process_map('sf_sample.osm', False)\n",
    "    \n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually check that the cleaning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'San Francisco', 'state': 'CA', 'street': 'Haight Street', 'housenumber': '1398', 'zip': '94117'}\n",
      "{'street': 'Sacramento Street', 'housenumber': '500'}\n",
      "{'city': 'Berkeley', 'state': 'CA', 'street': 'University Avenue', 'housenumber': '2000', 'country': 'US'}\n",
      "{'street': '16th Street', 'housenumber': '3121'}\n",
      "{'city': 'Alameda', 'street': 'Park Street', 'housenumber': '1223', 'zip': '94501'}\n",
      "{'city': 'Berkeley', 'street': 'Shattuck Avenue', 'housenumber': '1988'}\n",
      "{'street': '3rd Street', 'housenumber': '590', 'zip': '94107'}\n",
      "{'street': 'Euclid Avenue'}\n",
      "{'street': 'Euclid Avenue'}\n",
      "{'county': 'San Mateo', 'state': 'CA'}\n",
      "{'street': 'Stockton Street', 'housenumber': '1556'}\n",
      "{'city': 'San Francisco', 'state': 'CA', 'street': 'Sacramento Street', 'housenumber': '3233', 'zip': '94115'}\n",
      "{'street': 'Kearny Street', 'housenumber': '1260'}\n",
      "{'street': 'Floribunda Avenue'}\n",
      "{'city': 'Berkeley', 'street': 'Solano Avenue', 'housenumber': '1892'}\n",
      "{'city': 'Albany', 'state': 'CA', 'street': 'Solano Avenue', 'housenumber': '1166', 'zip': '94706'}\n",
      "{'street': 'Natoma Street', 'housenumber': '431'}\n",
      "{'city': 'Berkeley', 'state': 'CA', 'street': 'San Pablo Avenue', 'housenumber': '1822', 'country': 'US'}\n",
      "{'street': 'Center Street', 'housenumber': '2146'}\n",
      "{'street': 'Green Street', 'housenumber': '271'}\n",
      "{'street': 'Alameda de Las Pulgas', 'housenumber': '600'}\n",
      "{'city': 'Sausalito', 'street': 'Litho Street', 'housenumber': '420', 'zip': '94965'}\n",
      "{'city': 'Hayward', 'state': 'CA', 'street': 'Palisade Street', 'housenumber': '951', 'zip': '94542'}\n",
      "{'street': 'Radio Road', 'housenumber': '900'}\n",
      "{'city': 'Richmond', 'street': 'South 19th Street', 'housenumber': '607'}\n",
      "{'city': 'Richmond', 'street': 'Macdonald Avenue', 'housenumber': '3501'}\n",
      "{'city': 'Richmond', 'street': 'Cutting Boulevard', 'housenumber': '3911'}\n",
      "{'street': 'Skyline Boulevard', 'housenumber': '6565'}\n",
      "{'street': 'Fairfax Avenue', 'housenumber': '2600'}\n",
      "{'street': 'Montgomery Street', 'housenumber': '1132'}\n"
     ]
    }
   ],
   "source": [
    "# Visually Check address keys\n",
    "allzip = defaultdict(int)\n",
    "count=0\n",
    "for d in data:\n",
    "    #print v\n",
    "    for k in d:\n",
    "        if k ==\"address\":\n",
    "            if count<30:\n",
    "                print d[k]\n",
    "                count+=1\n",
    "    \n",
    "    \n",
    "    #print data[][\"address\"][\"zip\"]\n",
    "    #allzip[v]+=1\n",
    "    #print v\n",
    "\n",
    "#print allzip \n",
    "#print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Value in for building key : building\n",
      "----------------------------------------\n",
      "shop\n",
      "shed\n",
      "industrial\n",
      "portable\n",
      "office\n",
      "apartments\n",
      "house\n",
      "condominiums\n",
      "mixed_use\n",
      "medical\n",
      "guardhouse\n",
      "college\n",
      "greenhouse\n",
      "church\n",
      "yes\n",
      "portables\n",
      "hangar\n",
      "kindergarten\n",
      "stands\n",
      "no\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : building:height\n",
      "----------------------------------------\n",
      "126\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : building:part\n",
      "----------------------------------------\n",
      "cathedral\n",
      "yes\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : building:colour\n",
      "----------------------------------------\n",
      "gray\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : building:levels\n",
      "----------------------------------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "14\n",
      "15\n",
      "18\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : building:material\n",
      "----------------------------------------\n",
      "wood;stucco\n",
      "wood;brick\n",
      "wood;stucco;brick\n",
      "masonry;wood\n",
      "concrete\n",
      "wood\n",
      "----------------------------------------\n",
      "Distinct Value in for building key : rwc_ca:buildingid\n",
      "----------------------------------------\n",
      "8170\n",
      "33360\n",
      "33352\n",
      "8747\n",
      "8278\n",
      "9532\n",
      "32648\n",
      "33343\n",
      "8349\n",
      "33376\n",
      "8295\n",
      "8139\n",
      "8296\n",
      "8299\n",
      "8782\n",
      "25375\n",
      "8785\n",
      "8190\n",
      "8195\n",
      "1967\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Visually Check building values\n",
    "building = defaultdict(set)\n",
    "count=0\n",
    "for d in data:\n",
    "    \n",
    "    #print v\n",
    "    for k in d:\n",
    "        if \"building\" in k:\n",
    "                building[k].add(d[k])\n",
    "                \n",
    "for k in building:\n",
    "    count1=0\n",
    "    print 'Distinct Value in for building key :',k\n",
    "    print '----------------------------------------'\n",
    "    for a in building[k]:        \n",
    "        if count1<20:            \n",
    "            print a\n",
    "            count1+=1\n",
    "            \n",
    "    print '----------------------------------------'\n",
    "    \n",
    "    \n",
    "    #print data[][\"address\"][\"zip\"]\n",
    "    #allzip[v]+=1\n",
    "    #print v\n",
    "\n",
    "#print allzip \n",
    "#print type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('94122', 525)\n",
      "1 ('94611', 344)\n",
      "2 ('94116', 258)\n",
      "3 ('94610', 172)\n",
      "4 ('94117', 151)\n",
      "5 ('94133', 150)\n",
      "6 ('94118', 140)\n",
      "7 ('94080', 111)\n",
      "8 ('94127', 105)\n",
      "9 ('94541', 103)\n",
      "10 ('94103', 95)\n",
      "11 ('94587', 94)\n",
      "12 ('94546', 83)\n",
      "13 ('94010', 82)\n",
      "14 ('94605', 82)\n",
      "15 ('94063', 81)\n",
      "16 ('94501', 78)\n",
      "17 ('94544', 78)\n",
      "18 ('94560', 75)\n",
      "19 ('94555', 72)\n",
      "20 ('94110', 71)\n"
     ]
    }
   ],
   "source": [
    "# Most common zip-codes\n",
    "allzip = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    #print v\n",
    "    for k in d:\n",
    "        if k ==\"address\":\n",
    "                for j in d[k]:\n",
    "                    if j == 'zip':\n",
    "                            allzip[d[k][j]]+=1\n",
    "#print allzip\n",
    "print_sorted_list(allzip, 'Top 20 zip values')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load cleaned JSON data into MongoDB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data into MongoDB instance\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "\n",
    "# Drop database if exists\n",
    "#db.osm_col.drop()\n",
    "\n",
    "db = client.osm_col\n",
    "#osm_col = db.osm_col\n",
    "db.osm_col.insert_many(data)\n",
    "\n",
    "\n",
    "print db.osm_col.count()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
